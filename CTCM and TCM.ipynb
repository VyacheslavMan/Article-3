{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34765c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "from urllib.request import urlopen\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "    \n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import pywt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5725adf",
   "metadata": {},
   "source": [
    "# TCM, CTCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import solve\n",
    "\n",
    "\n",
    "def my_method_1(index_list, len_wind, step_smooth):\n",
    "    prognoz=[]\n",
    "    \n",
    "    train=index_list\n",
    "#     iteratation_5=int((len(index_list)-len_wind)/step_smooth)+1\n",
    "    iteratation_5=1\n",
    "\n",
    "    itog_prog=[]\n",
    "    for i in range(0,iteratation_5):\n",
    "#         train=index_list[0+step_smooth*i:len_wind+step_smooth*i] \n",
    "\n",
    "\n",
    "\n",
    "        t=len(train)\n",
    "\n",
    "        y1=[]\n",
    "        y2=[]\n",
    "        y3=[]\n",
    "        y4=[]\n",
    "\n",
    "        y_ist=[]\n",
    "        y_ist.append(train[0])\n",
    "\n",
    "        y_prog=[]\n",
    "        y_prog.append(train[0])\n",
    "        y_prog.append(train[1])\n",
    "\n",
    "\n",
    "        y1.append(train[0])#\n",
    "        y2.append(0)#Изменение\n",
    "        y3.append(train[0]-y_prog[0])# ошибка прошлого прогноза\n",
    "        y4.append(0)# ошибка изменения\n",
    "\n",
    "\n",
    "        for i in range(1,t-1):\n",
    "\n",
    "            y_ist.append(train[i+1])\n",
    "            y1.append(train[i])\n",
    "            y2.append(train[i]-train[i-1])#izmeneniya\n",
    "            y3.append(train[i]-y_prog[i])#err\n",
    "            y4.append(train[i]-train[i-1]-y_prog[i]+y_prog[i-1])#err izmeneniya\n",
    "\n",
    "            y=np.array([y1,\n",
    "                y2,\n",
    "                y3,\n",
    "                y4])\n",
    "\n",
    "            m_y=np.dot(y,y.T)\n",
    "\n",
    "            if i<3:\n",
    "                m_y=m_y+np.diag(np.full(4,1))\n",
    "            else:\n",
    "                m_y=m_y  \n",
    "\n",
    "        #     y_t=y1[-1]\n",
    "\n",
    "\n",
    "            mb_y=np.dot(y,y_ist)\n",
    "\n",
    "            resh=solve(m_y, mb_y)\n",
    "\n",
    "            y_prog.append(resh[0]*y1[-1]+resh[1]*y2[-1]+resh[2]*y3[-1]+resh[3]*y4[-1])\n",
    "\n",
    "        #     print(i)\n",
    "\n",
    "        i=t-1\n",
    "        y_ist.append(train[t-1])\n",
    "        y1.append(train[i])\n",
    "        y2.append(train[i]-train[i-1])#izmeneniya\n",
    "        y3.append(train[i]-y_prog[i])#err\n",
    "        y4.append(train[i]-train[i-1]-y_prog[i]+y_prog[i-1])#err izmeneniya\n",
    "\n",
    "        y=np.array([y1,\n",
    "                y2,\n",
    "                y3,\n",
    "                y4])\n",
    "\n",
    "        m_y=np.dot(y,y.T)\n",
    "\n",
    "        if i<3:\n",
    "            m_y=m_y+np.diag(np.full(4,1))\n",
    "        else:\n",
    "            m_y=m_y  \n",
    "\n",
    "        #     y_t=y1[-1]\n",
    "\n",
    "\n",
    "        mb_y=np.dot(y,y_ist)\n",
    "\n",
    "        resh=solve(m_y, mb_y)\n",
    "\n",
    "        y_prog.append(resh[0]*y1[-1]+resh[1]*y2[-1]+resh[2]*y3[-1]+resh[3]*y4[-1])\n",
    "        prognoz.append(y_prog[-1])\n",
    "    return prognoz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81d1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_method_1_correct(index_list, len_wind, step_smooth, persentile):\n",
    "    prognoz=[]\n",
    "\n",
    "    train=index_list\n",
    "#     iteratation_5=int((len(index_list)-len_wind)/step_smooth)+1\n",
    "    iteratation_5=1\n",
    "\n",
    "    prognoz_correct=[]\n",
    "    itog_prog=[]\n",
    "    for i in range(0,iteratation_5):\n",
    "#         train=index_list[0+step_smooth*i:len_wind+step_smooth*i] \n",
    "\n",
    "\n",
    "\n",
    "        t=len(train)\n",
    "\n",
    "        y1=[]\n",
    "        y2=[]\n",
    "        y3=[]\n",
    "        y4=[]\n",
    "\n",
    "        y_ist=[]\n",
    "        y_ist.append(train[0])\n",
    "\n",
    "        y_prog=[]\n",
    "        y_prog.append(train[0])\n",
    "        y_prog.append(train[1])\n",
    "\n",
    "\n",
    "        y1.append(train[0])#\n",
    "        y2.append(0)#Изменение\n",
    "        y3.append(train[0]-y_prog[0])#\n",
    "        y4.append(0)# \n",
    "\n",
    "        tmp_prog=[]\n",
    "        for i in range(1,t-1):\n",
    "\n",
    "            y_ist.append(train[i+1])\n",
    "            y1.append(train[i])\n",
    "            y2.append(train[i]-train[i-1])#izmeneniya\n",
    "            y3.append(train[i]-y_prog[i])#err\n",
    "            y4.append(train[i]-train[i-1]-y_prog[i]+y_prog[i-1])#err izmeneniya\n",
    "\n",
    "            y=np.array([y1,\n",
    "                y2,\n",
    "                y3,\n",
    "                y4])\n",
    "\n",
    "            m_y=np.dot(y,y.T)\n",
    "\n",
    "            if i<3:\n",
    "                m_y=m_y+np.diag(np.full(4,1))\n",
    "            else:\n",
    "                m_y=m_y  \n",
    "\n",
    "        #     y_t=y1[-1]\n",
    "\n",
    "\n",
    "            mb_y=np.dot(y,y_ist)\n",
    "\n",
    "#             resh=solve(m_y, mb_y)\n",
    "            while True:\n",
    "                try:\n",
    "                    resh=solve(m_y, mb_y)\n",
    "                    break\n",
    "                except Exception as exc:\n",
    "                    resh=solve(m_y+np.diag(np.full(4,1)), mb_y)\n",
    "                    break\n",
    "\n",
    "            y_prog.append(resh[0]*y1[-1]+resh[1]*y2[-1]+resh[2]*y3[-1]+resh[3]*y4[-1])\n",
    "            tmp_prog.append(resh[0]*y1[-1]+resh[1]*y2[-1]+resh[2]*y3[-1]+resh[3]*y4[-1])\n",
    "\n",
    "\n",
    "        tmp_mape_vec=((np.array(tmp_prog)-np.array(train[-len(tmp_prog)-1:-1]))/np.array(train[-len(tmp_prog)-1:-1]))\n",
    "        tmp_mape=tmp_mape_vec.mean()\n",
    "        i=t-1\n",
    "        y_ist.append(train[t-1])\n",
    "        y1.append(train[i])\n",
    "        y2.append(train[i]-train[i-1])#izmeneniya\n",
    "        y3.append(train[i]-y_prog[i])#err\n",
    "        y4.append(train[i]-train[i-1]-y_prog[i]+y_prog[i-1])#err izmeneniya\n",
    "\n",
    "        y=np.array([y1,\n",
    "                y2,\n",
    "                y3,\n",
    "                y4])\n",
    "\n",
    "        m_y=np.dot(y,y.T)\n",
    "\n",
    "        if i<3:\n",
    "            m_y=m_y+np.diag(np.full(4,1))\n",
    "        else:\n",
    "            m_y=m_y  \n",
    "\n",
    "        #     y_t=y1[-1]\n",
    "\n",
    "\n",
    "        mb_y=np.dot(y,y_ist)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                resh=solve(m_y, mb_y)\n",
    "    #                 all_fr=pd.concat([all_fr,tmp])\n",
    "    #                 print(i+'_'+j)\n",
    "                break\n",
    "            except Exception as exc:\n",
    "                resh=solve(m_y+np.diag(np.full(4,1)), mb_y)\n",
    "                break\n",
    "#         resh=solve(m_y+np.diag(np.full(4,1)), mb_y) \n",
    "        \n",
    "#         resh=solve(m_y, mb_y)\n",
    "\n",
    "        y_prog.append(resh[0]*y1[-1]+resh[1]*y2[-1]+resh[2]*y3[-1]+resh[3]*y4[-1])\n",
    "\n",
    "\n",
    "        prognoz.append(y_prog[-1])\n",
    "        prognoz_correct.append(y_prog[-1]*(1+np.percentile(tmp_mape_vec, persentile)))#\n",
    "#         prognoz_correct.append(y_prog[-1]*(1+np.percentile(np.array(pd.DataFrame(tmp_mape_vec).dropna()), persentile)))#\n",
    "    return prognoz, prognoz_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f121999a",
   "metadata": {},
   "source": [
    "# with wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5bbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "len_wind=399\n",
    "step_smooth=1\n",
    "# index_list=frame_3.NI.dropna()\n",
    "wavelet='bior5.5'\n",
    "modes='smooth'\n",
    "\n",
    "def perebor_levels_wavedec_without_noise_naiv_1(index_list, len_wind, step_smooth, wavelet, modes):\n",
    "# for kk in range(0,1):\n",
    "    dates=index_list.index\n",
    "#     prog1=[]\n",
    "#     prog11=[]\n",
    "    levl=pywt.dwt_max_level(len_wind, wavelet)\n",
    "    if levl>7:\n",
    "        levl=7\n",
    "    \n",
    "    iteratation_5=int((len(index_list)-len_wind)/step_smooth)\n",
    "#     iteratation_5=5\n",
    "    name=[]\n",
    "    frame_prog_tcm=pd.DataFrame()\n",
    "    frame_prog_ctcm=pd.DataFrame()\n",
    "    for k in range(1,levl+1):\n",
    "        \n",
    "        lvl=k\n",
    "        prog1=[]\n",
    "        prog11=[]\n",
    "#         toch=[]\n",
    "        date=[]\n",
    "        date1=[]\n",
    "    \n",
    "#         naiv=[]\n",
    "        name.append(wavelet+'_'+modes+'_'+str(lvl))\n",
    "        for i in range(0,iteratation_5):\n",
    "    \n",
    "            train=index_list[0+step_smooth*i:len_wind+step_smooth*i]\n",
    "            A2= pywt.wavedec(train, wavelet, level=lvl, mode=modes)\n",
    "            razl=A2[0]\n",
    "            tmp=my_method_1_correct(razl, len_wind, step_smooth, persentile=0.8)\n",
    "        \n",
    "        \n",
    "#         TCM\n",
    "            arr=[ x for x in range(lvl+1)]\n",
    "            arr[0]=np.append(razl,tmp[0][0])[1:]\n",
    "            \n",
    "            for j in range(1,lvl+1):\n",
    "                arr[j]=None\n",
    "            coeff_new=arr\n",
    "            denoised_index = pywt.waverec(coeff_new, wavelet, mode=modes)\n",
    "            date.append(dates[0+step_smooth*i:len_wind+1+step_smooth*i][-1:][0])\n",
    "            prog1.append(denoised_index[-1])\n",
    "            \n",
    "#         CTCM\n",
    "            arr1=[ x for x in range(lvl+1)]\n",
    "            arr1[0]=np.append(razl,tmp[1][0])[1:]\n",
    "            \n",
    "            for j in range(1,lvl+1):\n",
    "                arr1[j]=None\n",
    "            coeff_new1=arr1\n",
    "            denoised_index1 = pywt.waverec(coeff_new1, wavelet, mode=modes)\n",
    "            date1.append(dates[0+step_smooth*i:len_wind+1+step_smooth*i][-1:][0])\n",
    "            prog11.append(denoised_index1[-1])\n",
    "            \n",
    "            \n",
    "        frame_prog_tcm[wavelet+'_'+modes+'_'+str(k)]=prog1\n",
    "        frame_prog_ctcm[wavelet+'_'+modes+'_'+str(k)]=prog11\n",
    "    frame_prog_tcm.index=date\n",
    "    frame_prog_ctcm.index=date1\n",
    "    return frame_prog_tcm, frame_prog_ctcm\n",
    "\n",
    "def toch_f(index_list, len_wind, step_smooth):\n",
    "    dates=index_list.index    \n",
    "    iteratation_5=int((len(index_list)-len_wind)/step_smooth)\n",
    "    frame_prog=pd.DataFrame()\n",
    "    toch=[]\n",
    "    date=[]\n",
    "    \n",
    "    for i in range(0,iteratation_5):\n",
    "        train=index_list[0+step_smooth*i:len_wind+step_smooth*i]\n",
    "        toch.append(index_list[0+step_smooth*i:len_wind+1+step_smooth*i][-1:].values[0])\n",
    "        date.append(dates[0+step_smooth*i:len_wind+1+step_smooth*i][-1:][0])\n",
    "    frame_prog['orig']=toch\n",
    "    frame_prog.index=date\n",
    "    return frame_prog    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes=['symmetric',\n",
    "       'reflect',\n",
    "       'smooth',\n",
    "       'constant']\n",
    "\n",
    "wavelets=['haar',\n",
    " 'db1',\n",
    " 'db2',\n",
    " 'db3',\n",
    " 'db4',\n",
    " 'db5',\n",
    " 'db6',\n",
    " 'db7',\n",
    " 'db8',\n",
    " 'db9',\n",
    " 'db10',\n",
    " 'db11',\n",
    " 'db12',\n",
    " 'db13',\n",
    " 'db14',\n",
    " 'db15',\n",
    " 'db16',\n",
    " 'db17',\n",
    " 'db18',\n",
    " 'db19',\n",
    " 'db20',\n",
    " 'db21',\n",
    " 'db22',\n",
    " 'db23',\n",
    " 'db24',\n",
    " 'db25',\n",
    " 'db26',\n",
    " 'db27',\n",
    " 'db28',\n",
    " 'db29',\n",
    " 'db30',\n",
    " 'db31',\n",
    " 'db32',\n",
    " 'db33',\n",
    " 'db34',\n",
    " 'db35',\n",
    " 'db36',\n",
    " 'db37',\n",
    " 'db38',\n",
    " 'sym2',\n",
    " 'sym3',\n",
    " 'sym4',\n",
    " 'sym5',\n",
    " 'sym6',\n",
    " 'sym7',\n",
    " 'sym8',\n",
    " 'sym9',\n",
    " 'sym10',\n",
    " 'sym11',\n",
    " 'sym12',\n",
    " 'sym13',\n",
    " 'sym14',\n",
    " 'sym15',\n",
    " 'sym16',\n",
    " 'sym17',\n",
    " 'sym18',\n",
    " 'sym19',\n",
    " 'sym20',\n",
    " 'coif1',\n",
    " 'coif2',\n",
    " 'coif3',\n",
    " 'coif4',\n",
    " 'coif5',\n",
    " 'coif6',\n",
    " 'coif7',\n",
    " 'coif8',\n",
    " 'coif9',\n",
    " 'coif10',\n",
    " 'coif11',\n",
    " 'coif12',\n",
    " 'coif13',\n",
    " 'coif14',\n",
    " 'coif15',\n",
    " 'coif16',\n",
    " 'coif17',\n",
    " 'bior1.1',\n",
    " 'bior1.3',\n",
    " 'bior1.5',\n",
    " 'bior2.2',\n",
    " 'bior2.4',\n",
    " 'bior2.6',\n",
    " 'bior2.8',\n",
    " 'bior3.1',\n",
    " 'bior3.3',\n",
    " 'bior3.5',\n",
    " 'bior3.7',\n",
    " 'bior3.9',\n",
    " 'bior4.4',\n",
    " 'bior5.5',\n",
    " 'bior6.8',\n",
    " 'rbio1.1',\n",
    " 'rbio1.3',\n",
    " 'rbio1.5',\n",
    " 'rbio2.2',\n",
    " 'rbio2.4',\n",
    " 'rbio2.6',\n",
    " 'rbio2.8',\n",
    " 'rbio3.1',\n",
    " 'rbio3.3',\n",
    " 'rbio3.5',\n",
    " 'rbio3.7',\n",
    " 'rbio3.9',\n",
    " 'rbio4.4',\n",
    " 'rbio5.5',\n",
    " 'rbio6.8',\n",
    " 'dmey']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f7ac6",
   "metadata": {},
   "source": [
    "# assets forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add6e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# act=['DHR', 'LIN', 'PL', 'GOOG', 'BTCUSD', 'CA', 'NI']\n",
    "\n",
    "act=['DHR', 'LIN', 'PL', 'GOOG', 'BTCUSD', 'CA', 'NI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4642d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"your directory\")\n",
    "frame=pd.read_csv('close_frame.csv', delimiter=';')\n",
    "\n",
    "frame_3=frame.copy()\n",
    "frame_3.index=np.array(frame_3[frame_3.columns[0]])\n",
    "frame_3=frame_3.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335732eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"your directory for predict\")\n",
    "\n",
    "\n",
    "step_smooth=1\n",
    "len_wind=399\n",
    "for k in act:\n",
    "\n",
    "    index_list=frame_3[k].dropna()\n",
    "\n",
    "    all_fr_tcm=pd.DataFrame()\n",
    "    all_fr_ctcm=pd.DataFrame()\n",
    "    err=[]\n",
    "    err_reason=[]\n",
    "\n",
    "    for j in modes:\n",
    "        for i in wavelets:\n",
    "            while True:\n",
    "                try:\n",
    "                    print(k+'_'+i+'_'+j)\n",
    "                    tmp=perebor_levels_wavedec_without_noise_naiv_1(index_list, len_wind, step_smooth, wavelet=i, modes=j)\n",
    "    #                 all_fr=pd.concat([all_fr,tmp])\n",
    "#                     print(all_fr_tcm)\n",
    "                    clear_output()\n",
    "                    break\n",
    "                except Exception as exc:\n",
    "                    err.append(wavelets)\n",
    "                    err_reason.append(exc)\n",
    "                    break\n",
    "            all_fr_tcm=pd.concat([all_fr_tcm,tmp[0]], axis=1)\n",
    "            all_fr_ctcm=pd.concat([all_fr_ctcm,tmp[1]], axis=1)\n",
    "            print(all_fr_tcm)\n",
    "#             print(i+'_'+j)    \n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    all_fr_ctcm=pd.concat([all_fr_ctcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    print(k)\n",
    "#     all_fr\n",
    "    all_fr_tcm.to_csv('ts_TCM_without_noise_2_'+k+'.csv', sep=';', encoding='utf-8')\n",
    "    all_fr_ctcm.to_csv('ts_CTCM_without_noise_2_'+k+'.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190cce2c",
   "metadata": {},
   "source": [
    "# realized volatility forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f721c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "act=['MSFT',\n",
    " 'V',\n",
    " 'INTC',\n",
    " 'CMCSA',\n",
    " 'ADBE',\n",
    " 'CRM',\n",
    " 'XEL',\n",
    " 'AEP',\n",
    " 'AH',\n",
    " 'PLD',\n",
    " 'AMT',\n",
    " 'AMZN',\n",
    " 'GOOG',\n",
    " 'BAC',\n",
    " 'JPM',\n",
    " 'BRK+B',\n",
    " 'BTCUSD',\n",
    " 'ETHUSD',\n",
    " 'BZ',\n",
    " 'CL',\n",
    " 'CA',\n",
    " 'PSX',\n",
    " 'COP',\n",
    " 'MMM',\n",
    " 'UNP',\n",
    " 'XOM',\n",
    " 'CVX',\n",
    " 'NFLX',\n",
    " 'NVDA',\n",
    " 'GC',\n",
    " 'LOW',\n",
    " 'HD',\n",
    " 'HON',\n",
    " 'KO',\n",
    " 'PEP',\n",
    " 'NI',\n",
    " 'PA',\n",
    " 'PL',\n",
    " 'QUAL',\n",
    " 'XRPUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"your directory\")\n",
    "frame=pd.read_csv('rv_frame.csv', delimiter=';')\n",
    "frame_3=frame.copy()\n",
    "frame_3.index=np.array(frame_3[frame_3.columns[0]])\n",
    "frame_3=frame_3.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"your directory for predict\")\n",
    "\n",
    "step_smooth=1\n",
    "len_wind=399\n",
    "for k in act:\n",
    "\n",
    "    index_list=np.log(np.sqrt(frame_3[k].dropna()))\n",
    "\n",
    "    all_fr_tcm=pd.DataFrame()\n",
    "    all_fr_ctcm=pd.DataFrame()\n",
    "    err=[]\n",
    "    err_reason=[]\n",
    "\n",
    "    for j in modes:\n",
    "        for i in wavelets:\n",
    "            while True:\n",
    "                try:\n",
    "                    tmp=perebor_levels_wavedec_without_noise_naiv_1(index_list, len_wind, step_smooth, wavelet=i, modes=j)\n",
    "    #                 all_fr=pd.concat([all_fr,tmp])\n",
    "    #                 print(i+'_'+j)\n",
    "                    break\n",
    "                except Exception as exc:\n",
    "                    err.append(wavelets)\n",
    "                    err_reason.append(exc)\n",
    "                    break\n",
    "            all_fr_tcm=pd.concat([all_fr_tcm,tmp[0]], axis=1)\n",
    "            all_fr_ctcm=pd.concat([all_fr_ctcm,tmp[1]], axis=1)\n",
    "#             print(i+'_'+j)    \n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    all_fr_ctcm=pd.concat([all_fr_ctcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    print(k)\n",
    "#     all_fr\n",
    "    all_fr_tcm.to_csv('ts_rv_TCM_without_noise_1_'+k+'.csv', sep=';', encoding='utf-8')\n",
    "    all_fr_ctcm.to_csv('ts_rv_CTCM_without_noise_1_'+k+'.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d398d83",
   "metadata": {},
   "source": [
    "# without wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_my_meth(index_list, len_wind, step_smooth):\n",
    "    dates=index_list.index    \n",
    "    iteratation_5=int((len(index_list)-len_wind)/step_smooth)\n",
    "#     iteratation_5=5\n",
    "    name=[]\n",
    "    frame_prog_my_meth=pd.DataFrame()\n",
    "\n",
    "    prog1=[]\n",
    "    prog11=[]\n",
    "    date1=[]\n",
    "    \n",
    "    for i in range(0,iteratation_5):\n",
    "    \n",
    "        train=index_list[0+step_smooth*i:len_wind+step_smooth*i]\n",
    "\n",
    "        tmp=my_method_1_correct(train, len_wind, step_smooth, persentile=0.8)\n",
    "        \n",
    "#         TCM\n",
    "        prog1.append(tmp[0][0])\n",
    "#         CTCM    \n",
    "        prog11.append(tmp[1][0])\n",
    "\n",
    "        date1.append(dates[0+step_smooth*i:len_wind+1+step_smooth*i][-1:][0])      \n",
    "            \n",
    "    frame_prog_my_meth['TCM']=prog1\n",
    "    frame_prog_my_meth['CTCM']=prog11\n",
    "    frame_prog_my_meth.index=date1\n",
    "    return frame_prog_my_meth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8e93f",
   "metadata": {},
   "source": [
    "# assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c9f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "act=['DHR', 'LIN', 'PL', 'GOOG', 'BTCUSD', 'CA', 'NI']\n",
    "\n",
    "os.chdir(\"your directory\")\n",
    "frame=pd.read_csv('close_frame.csv', delimiter=';')\n",
    "\n",
    "frame_3=frame.copy()\n",
    "frame_3.index=np.array(frame_3[frame_3.columns[0]])\n",
    "frame_3=frame_3.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"your directory for predict\")\n",
    "\n",
    "step_smooth=1\n",
    "len_wind=399\n",
    "for k in act:\n",
    "\n",
    "    index_list=frame_3[k].dropna()\n",
    "\n",
    "    all_fr_tcm=pd.DataFrame()\n",
    "\n",
    "    tmp=all_my_meth(index_list, len_wind, step_smooth)\n",
    "\n",
    "    \n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,tmp], axis=1)\n",
    "\n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    \n",
    "    \n",
    "    print(k)\n",
    "    all_fr_tcm.to_csv('ts_my_meth_'+k+'.csv', sep=';', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ecb90",
   "metadata": {},
   "source": [
    "# realized volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d37c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "act=['MSFT',\n",
    " 'V',\n",
    " 'INTC',\n",
    " 'CMCSA',\n",
    " 'ADBE',\n",
    " 'CRM',\n",
    " 'XEL',\n",
    " 'AEP',\n",
    " 'AH',\n",
    " 'PLD',\n",
    " 'AMT',\n",
    " 'AMZN',\n",
    " 'GOOG',\n",
    " 'BAC',\n",
    " 'JPM',\n",
    " 'BRK+B',\n",
    " 'BTCUSD',\n",
    " 'ETHUSD',\n",
    " 'BZ',\n",
    " 'CL',\n",
    " 'CA',\n",
    " 'PSX',\n",
    " 'COP',\n",
    " 'MMM',\n",
    " 'UNP',\n",
    " 'XOM',\n",
    " 'CVX',\n",
    " 'NFLX',\n",
    " 'NVDA',\n",
    " 'GC',\n",
    " 'LOW',\n",
    " 'HD',\n",
    " 'HON',\n",
    " 'KO',\n",
    " 'PEP',\n",
    " 'NI',\n",
    " 'PA',\n",
    " 'PL',\n",
    " 'QUAL',\n",
    " 'XRPUSD']\n",
    "\n",
    "\n",
    "os.chdir(\"your directory\")\n",
    "frame=pd.read_csv('rv_frame.csv', delimiter=';')\n",
    "frame_3=frame.copy()\n",
    "frame_3.index=np.array(frame_3[frame_3.columns[0]])\n",
    "frame_3=frame_3.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"your directory for predict\")\n",
    "\n",
    "\n",
    "step_smooth=1\n",
    "len_wind=399\n",
    "for k in act:\n",
    "\n",
    "    index_list=np.log(np.sqrt(frame_3[k].dropna()))\n",
    "\n",
    "    all_fr_tcm=pd.DataFrame()\n",
    "\n",
    "    tmp=all_my_meth(index_list, len_wind, step_smooth)\n",
    "\n",
    "    \n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,tmp], axis=1)\n",
    "\n",
    "    all_fr_tcm=pd.concat([all_fr_tcm,toch_f(index_list, len_wind, step_smooth)], axis=1)\n",
    "    \n",
    "    \n",
    "    print(k)\n",
    "    all_fr_tcm.to_csv('ts_rv_my_meth_'+k+'.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6895af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
